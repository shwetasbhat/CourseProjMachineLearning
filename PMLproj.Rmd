---
title: "PracticalMachineLearningProject"
output: html_document
---
# Practical machine learning course project
Shweta

## Summary

In this project, we will be using data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways.The goal of this project is to predict the manner in which they did the exercise. This is the "classe" variable in the training set.

## Reading the data

Let us start off by loading the training and test data.
```{r dataloading}
library(caret)
training_pj <- read.csv("C:/DSTCourse/pml-training.csv",header = TRUE,na.strings = c("NA","",'#DIV/0!'))
testing_pj <- read.csv("C:/DSTCourse/pml-testing.csv", header = TRUE,na.strings = c("NA","",'#DIV/0!'))
dim(training_pj)
dim(testing_pj)
```

## Data cleaning and preprocessing
```{r datacleaning}
training_pj <- training_pj[,(colSums(is.na(training_pj)) == 0)]

testing_pj <- testing_pj[,(colSums(is.na(testing_pj)) == 0)]
```

```{r preprocess}
numId <- which(lapply(training_pj, class) %in% "numeric")

preprocessModel <- preProcess(training_pj[,numId],method=c('knnImpute', 'center', 'scale'))
training_preProc <- predict(preprocessModel, training_pj[,numId])
training_preProc$classe <- training_pj$classe

testing_preProc <- predict(preprocessModel,testing_pj[,numId])
```
We will not including the near zero variables in the prediction.
```{r removeNonZero}
nzv <- nearZeroVar(training_preProc,saveMetrics=TRUE)
training_preProc <- training_preProc[,nzv$nzv==FALSE]
nzv <- nearZeroVar(testing_preProc,saveMetrics=TRUE)
testing_preProc <- testing_preProc[,nzv$nzv==FALSE]
```

We will now load the required libraries and partition the data into training and validation set
```{r datapartition}

inTrain <- createDataPartition(training_preProc$classe, p = 3/4, list = FALSE)
training1 <- training_preProc[inTrain,]
validation1 <- training_preProc[-inTrain,]
dim(validation1)
```
# Training model

We will train a model using random forest with a cross validation of 5 folds to avoid overfitting.
```{r trainModel}
library(randomForest)
modFitrf <- train(classe ~., method="rf", data=training1, trControl=trainControl(method='cv'), number=5, allowParallel=TRUE, importance=TRUE )
modFitrf
```

## Cross validation and out of sample error rate

Let us apply the training model on the validation database, to check its accuracy.
```{r predict}
pred_VRF <- predict(modFitrf, validation1)
conf <- confusionMatrix(validation1$classe, pred_VRF)
conf$table
```

We see that most predictions are correct in this model. The model accuracy and the out of sample error when applied to the validation data are as below:
```{r acc}
accur <- postResample(validation1$classe, pred_VRF)
modAccuracy <- accur[[1]]
modAccuracy
```
```{r outOfSampleError}
out_of_sample_error <- 1 - modAccuracy
out_of_sample_error
```

## Applying the model to the test data

```{r predictTest}
pred_final <- predict(modFitrf, testing_preProc)
pred_final
```

